{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnconda048fc75fe4ee43f1aa97608c8881ebba",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from model import BiLSTM_CRF\n",
    "from utils import prepare, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'path':'/home/peitian_zhang/Data/NER/labeled_train.txt',\n",
    "    'epochs': 200,\n",
    "    'batch_size': 100,\n",
    "    'embedding_dim': 300,\n",
    "    'hidden_dim': 150,\n",
    "    'device':'cuda:0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'<START>': 0,\n",
       " '<END>': 1,\n",
       " '<PAD>': 2,\n",
       " 'O': 3,\n",
       " 'B-C': 4,\n",
       " 'I-C': 5,\n",
       " 'B-A': 6,\n",
       " 'I-A': 7,\n",
       " 'B-O': 8,\n",
       " 'I-O': 9,\n",
       " 'B-M': 10,\n",
       " 'I-M': 11,\n",
       " 'B-P': 12,\n",
       " 'I-P': 13,\n",
       " 'B-N': 14,\n",
       " 'I-N': 15,\n",
       " 'B-D': 16,\n",
       " 'I-D': 17,\n",
       " 'B-S': 18,\n",
       " 'I-S': 19,\n",
       " 'B-L': 20,\n",
       " 'I-L': 21}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tag2idx, vocab, loader = prepare(hparams)\n",
    "hparams['vocab_size'] = len(vocab)\n",
    "hparams['seq_length'] = loader.dataset.max_length\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(hparams, tag2idx).to(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[21, 20, 20,  ...,  3, 21, 13],\n        [21,  3,  3,  ...,  3, 21, 13],\n        [21,  3,  3,  ...,  3, 21, 13],\n        ...,\n        [21, 20, 20,  ...,  3, 21, 13],\n        [21, 20, 20,  ...,  3, 21, 13],\n        [21, 20, 20,  ...,  3, 21, 13]], device='cuda:0') tensor([[ 3,  3,  3,  ...,  2,  2,  2],\n        [ 3,  3,  3,  ...,  2,  2,  2],\n        [14, 15, 15,  ...,  2,  2,  2],\n        ...,\n        [ 3,  3,  3,  ...,  2,  2,  2],\n        [ 8,  9,  9,  ...,  2,  2,  2],\n        [16, 17, 17,  ...,  2,  2,  2]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    record = next(iter(loader))\n",
    "    _, tag_seq = model(record['token'])\n",
    "    print(\"Prediction:{}\\n Ground Truth:{}\".format(tag_seq, record['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch 1 , step 9 , loss: 1358.4268: : 10it [00:03,  3.21it/s]\n",
      "epoch 2 , step 9 , loss: 818.9688: : 10it [00:03,  3.20it/s]\n",
      "epoch 3 , step 9 , loss: 233.4179: : 10it [00:03,  3.17it/s]\n",
      "epoch 4 , step 9 , loss: -379.6076: : 10it [00:02,  3.34it/s]\n",
      "epoch 5 , step 9 , loss: -1000.3245: : 10it [00:03,  3.14it/s]\n",
      "epoch 6 , step 9 , loss: -1653.9761: : 10it [00:02,  3.42it/s]\n",
      "epoch 7 , step 9 , loss: -2331.6022: : 10it [00:02,  3.41it/s]\n",
      "epoch 8 , step 9 , loss: -3020.8292: : 10it [00:03,  3.25it/s]\n",
      "epoch 9 , step 9 , loss: -3733.6577: : 10it [00:03,  3.09it/s]\n",
      "epoch 10 , step 9 , loss: -4429.4866: : 10it [00:02,  3.34it/s]\n",
      "epoch 11 , step 9 , loss: -5124.9079: : 10it [00:02,  3.41it/s]\n",
      "epoch 12 , step 9 , loss: -5812.1964: : 10it [00:02,  3.45it/s]\n",
      "epoch 13 , step 9 , loss: -6489.9605: : 10it [00:03,  3.09it/s]\n",
      "epoch 14 , step 9 , loss: -7159.4641: : 10it [00:03,  3.06it/s]\n",
      "epoch 15 , step 9 , loss: -7822.5516: : 10it [00:03,  3.05it/s]\n",
      "epoch 16 , step 9 , loss: -8479.5468: : 10it [00:02,  3.35it/s]\n",
      "epoch 17 , step 9 , loss: -9131.2131: : 10it [00:03,  3.33it/s]\n",
      "epoch 18 , step 9 , loss: -9779.8716: : 10it [00:03,  3.30it/s]\n",
      "epoch 19 , step 9 , loss: -10424.4367: : 10it [00:02,  3.47it/s]\n",
      "epoch 20 , step 9 , loss: -11089.7683: : 10it [00:03,  3.24it/s]\n",
      "epoch 21 , step 9 , loss: -11742.3094: : 10it [00:02,  3.35it/s]\n",
      "epoch 22 , step 9 , loss: -12387.5969: : 10it [00:02,  3.43it/s]\n",
      "epoch 23 , step 9 , loss: -13030.5493: : 10it [00:02,  3.41it/s]\n",
      "epoch 24 , step 9 , loss: -13671.7698: : 10it [00:02,  3.46it/s]\n",
      "epoch 25 , step 9 , loss: -14308.1822: : 10it [00:02,  3.44it/s]\n",
      "epoch 26 , step 9 , loss: -14944.3471: : 10it [00:03,  3.01it/s]\n",
      "epoch 27 , step 9 , loss: -15578.4547: : 10it [00:02,  3.39it/s]\n",
      "epoch 28 , step 9 , loss: -16203.4320: : 10it [00:02,  3.38it/s]\n",
      "epoch 29 , step 9 , loss: -16832.4752: : 10it [00:02,  3.47it/s]\n",
      "epoch 30 , step 9 , loss: -17461.1631: : 10it [00:02,  3.44it/s]\n",
      "epoch 31 , step 9 , loss: -18090.1729: : 10it [00:02,  3.41it/s]\n",
      "epoch 32 , step 9 , loss: -18719.1871: : 10it [00:02,  3.43it/s]\n",
      "epoch 33 , step 9 , loss: -19349.1418: : 10it [00:02,  3.45it/s]\n",
      "epoch 34 , step 9 , loss: -19977.9148: : 10it [00:02,  3.44it/s]\n",
      "epoch 35 , step 9 , loss: -20605.7453: : 10it [00:02,  3.46it/s]\n",
      "epoch 36 , step 9 , loss: -21231.6646: : 10it [00:02,  3.36it/s]\n",
      "epoch 37 , step 9 , loss: -21859.1166: : 10it [00:02,  3.43it/s]\n",
      "epoch 38 , step 9 , loss: -22481.8551: : 10it [00:02,  3.41it/s]\n",
      "epoch 39 , step 9 , loss: -23105.7729: : 10it [00:02,  3.35it/s]\n",
      "epoch 40 , step 9 , loss: -23729.6240: : 10it [00:02,  3.39it/s]\n",
      "epoch 41 , step 9 , loss: -24348.9855: : 10it [00:02,  3.40it/s]\n",
      "epoch 42 , step 9 , loss: -24967.1980: : 10it [00:03,  3.12it/s]\n",
      "epoch 43 , step 9 , loss: -25586.9660: : 10it [00:02,  3.44it/s]\n",
      "epoch 44 , step 9 , loss: -26201.2381: : 10it [00:02,  3.42it/s]\n",
      "epoch 45 , step 9 , loss: -26811.6180: : 10it [00:02,  3.43it/s]\n",
      "epoch 46 , step 9 , loss: -27424.5316: : 10it [00:02,  3.42it/s]\n",
      "epoch 47 , step 9 , loss: -28039.5414: : 10it [00:02,  3.48it/s]\n",
      "epoch 48 , step 9 , loss: -28659.7004: : 10it [00:03,  2.94it/s]\n",
      "epoch 49 , step 9 , loss: -29276.3090: : 10it [00:03,  3.25it/s]\n",
      "epoch 50 , step 9 , loss: -29889.9344: : 10it [00:02,  3.41it/s]\n",
      "epoch 51 , step 9 , loss: -30508.3635: : 10it [00:02,  3.44it/s]\n",
      "epoch 52 , step 9 , loss: -31127.3045: : 10it [00:02,  3.45it/s]\n",
      "epoch 53 , step 9 , loss: -31747.6811: : 10it [00:02,  3.34it/s]\n",
      "epoch 54 , step 9 , loss: -32361.1305: : 10it [00:02,  3.35it/s]\n",
      "epoch 55 , step 9 , loss: -32980.8746: : 10it [00:03,  3.13it/s]\n",
      "epoch 56 , step 9 , loss: -33598.8605: : 10it [00:03,  2.98it/s]\n",
      "epoch 57 , step 9 , loss: -34212.6352: : 10it [00:04,  2.46it/s]\n",
      "epoch 58 , step 9 , loss: -34825.8844: : 10it [00:03,  3.19it/s]\n",
      "epoch 59 , step 9 , loss: -35447.1746: : 10it [00:03,  3.33it/s]\n",
      "epoch 60 , step 9 , loss: -36068.8340: : 10it [00:02,  3.36it/s]\n",
      "epoch 61 , step 9 , loss: -36681.3641: : 10it [00:02,  3.38it/s]\n",
      "epoch 62 , step 9 , loss: -37284.2312: : 10it [00:03,  3.31it/s]\n",
      "epoch 63 , step 9 , loss: -37899.9449: : 10it [00:02,  3.35it/s]\n",
      "epoch 64 , step 9 , loss: -38518.1430: : 10it [00:02,  3.34it/s]\n",
      "epoch 65 , step 9 , loss: -39125.3355: : 10it [00:02,  3.35it/s]\n",
      "epoch 66 , step 9 , loss: -39721.8250: : 10it [00:03,  3.00it/s]\n",
      "epoch 67 , step 9 , loss: -40322.6629: : 10it [00:03,  2.93it/s]\n",
      "epoch 68 , step 9 , loss: -40936.3289: : 10it [00:03,  3.20it/s]\n",
      "epoch 69 , step 9 , loss: -41547.4559: : 10it [00:02,  3.41it/s]\n",
      "epoch 70 , step 9 , loss: -42161.8512: : 10it [00:02,  3.35it/s]\n",
      "epoch 71 , step 9 , loss: -42773.8852: : 10it [00:03,  3.29it/s]\n",
      "epoch 72 , step 9 , loss: -43387.0930: : 10it [00:02,  3.37it/s]\n",
      "epoch 73 , step 9 , loss: -44003.1195: : 10it [00:02,  3.37it/s]\n",
      "epoch 74 , step 9 , loss: -44618.2730: : 10it [00:02,  3.44it/s]\n",
      "epoch 75 , step 9 , loss: -45231.4664: : 10it [00:02,  3.36it/s]\n",
      "epoch 76 , step 9 , loss: -45839.9785: : 10it [00:02,  3.38it/s]\n",
      "epoch 77 , step 9 , loss: -46443.1973: : 10it [00:03,  3.32it/s]\n",
      "epoch 78 , step 9 , loss: -47051.6691: : 10it [00:02,  3.36it/s]\n",
      "epoch 79 , step 9 , loss: -47662.2074: : 10it [00:02,  3.40it/s]\n",
      "epoch 80 , step 9 , loss: -48267.9793: : 10it [00:02,  3.39it/s]\n",
      "epoch 81 , step 9 , loss: -48879.0418: : 10it [00:02,  3.46it/s]\n",
      "epoch 82 , step 9 , loss: -49495.4242: : 10it [00:02,  3.41it/s]\n",
      "epoch 83 , step 9 , loss: -50110.2262: : 10it [00:02,  3.37it/s]\n",
      "epoch 84 , step 9 , loss: -50722.1211: : 10it [00:03,  3.32it/s]\n",
      "epoch 85 , step 9 , loss: -51329.7277: : 10it [00:02,  3.39it/s]\n",
      "epoch 86 , step 9 , loss: -51939.0676: : 10it [00:02,  3.45it/s]\n",
      "epoch 87 , step 9 , loss: -52550.6223: : 10it [00:02,  3.54it/s]\n",
      "epoch 88 , step 9 , loss: -53148.0316: : 10it [00:02,  3.48it/s]\n",
      "epoch 89 , step 9 , loss: -53740.3465: : 10it [00:03,  3.26it/s]\n",
      "epoch 90 , step 9 , loss: -54338.6957: : 10it [00:02,  3.36it/s]\n",
      "epoch 91 , step 9 , loss: -54944.5516: : 10it [00:02,  3.49it/s]\n",
      "epoch 92 , step 9 , loss: -55549.5984: : 10it [00:02,  3.38it/s]\n",
      "epoch 93 , step 9 , loss: -56150.1195: : 10it [00:02,  3.42it/s]\n",
      "epoch 94 , step 9 , loss: -56757.4664: : 10it [00:02,  3.39it/s]\n",
      "epoch 95 , step 9 , loss: -57365.7887: : 10it [00:03,  3.33it/s]\n",
      "epoch 96 , step 9 , loss: -57974.4203: : 10it [00:02,  3.35it/s]\n",
      "epoch 97 , step 9 , loss: -58593.8352: : 10it [00:03,  3.15it/s]\n",
      "epoch 98 , step 9 , loss: -59213.1684: : 10it [00:03,  2.72it/s]\n",
      "epoch 99 , step 9 , loss: -59830.7941: : 10it [00:03,  2.67it/s]\n",
      "epoch 100 , step 9 , loss: -60443.7141: : 10it [00:03,  2.70it/s]\n",
      "epoch 101 , step 9 , loss: -61053.6926: : 10it [00:03,  3.26it/s]\n",
      "epoch 102 , step 9 , loss: -61664.5441: : 10it [00:02,  3.39it/s]\n",
      "epoch 103 , step 9 , loss: -62272.0930: : 10it [00:02,  3.38it/s]\n",
      "epoch 104 , step 9 , loss: -62880.4457: : 10it [00:02,  3.44it/s]\n",
      "epoch 105 , step 9 , loss: -63487.1477: : 10it [00:02,  3.38it/s]\n",
      "epoch 106 , step 9 , loss: -64084.4305: : 10it [00:02,  3.42it/s]\n",
      "epoch 107 , step 9 , loss: -64684.0246: : 10it [00:03,  3.27it/s]\n",
      "epoch 108 , step 9 , loss: -65285.0887: : 10it [00:03,  3.31it/s]\n",
      "epoch 109 , step 9 , loss: -65892.9191: : 10it [00:02,  3.46it/s]\n",
      "epoch 110 , step 9 , loss: -66502.8617: : 10it [00:02,  3.36it/s]\n",
      "epoch 111 , step 9 , loss: -67112.6023: : 10it [00:02,  3.45it/s]\n",
      "epoch 112 , step 9 , loss: -67716.6148: : 10it [00:03,  3.17it/s]\n",
      "epoch 113 , step 9 , loss: -68324.6734: : 10it [00:02,  3.40it/s]\n",
      "epoch 114 , step 9 , loss: -68930.8070: : 10it [00:02,  3.34it/s]\n",
      "epoch 115 , step 9 , loss: -69538.3922: : 10it [00:02,  3.35it/s]\n",
      "epoch 116 , step 9 , loss: -70153.2609: : 10it [00:02,  3.39it/s]\n",
      "epoch 117 , step 9 , loss: -70764.4781: : 10it [00:03,  3.31it/s]\n",
      "epoch 118 , step 9 , loss: -71370.6406: : 10it [00:02,  3.44it/s]\n",
      "epoch 119 , step 9 , loss: -71975.4945: : 10it [00:02,  3.43it/s]\n",
      "epoch 120 , step 9 , loss: -72568.2375: : 10it [00:02,  3.41it/s]\n",
      "epoch 121 , step 9 , loss: -73165.4000: : 10it [00:02,  3.41it/s]\n",
      "epoch 122 , step 9 , loss: -73765.5961: : 10it [00:02,  3.46it/s]\n",
      "epoch 123 , step 9 , loss: -74377.1523: : 10it [00:02,  3.41it/s]\n",
      "epoch 124 , step 9 , loss: -74989.2570: : 10it [00:02,  3.42it/s]\n",
      "epoch 125 , step 9 , loss: -75605.3320: : 10it [00:03,  3.30it/s]\n",
      "epoch 126 , step 9 , loss: -76218.0977: : 10it [00:02,  3.34it/s]\n",
      "epoch 127 , step 9 , loss: -76817.4914: : 10it [00:02,  3.41it/s]\n",
      "epoch 128 , step 9 , loss: -77418.5867: : 10it [00:03,  2.99it/s]\n",
      "epoch 129 , step 9 , loss: -78019.2344: : 10it [00:02,  3.38it/s]\n",
      "epoch 130 , step 9 , loss: -78631.5961: : 10it [00:02,  3.39it/s]\n",
      "epoch 131 , step 9 , loss: -79242.8398: : 10it [00:02,  3.36it/s]\n",
      "epoch 132 , step 9 , loss: -79855.6859: : 10it [00:02,  3.34it/s]\n",
      "epoch 133 , step 9 , loss: -80469.7172: : 10it [00:03,  3.29it/s]\n",
      "epoch 134 , step 9 , loss: -81079.8289: : 10it [00:02,  3.48it/s]\n",
      "epoch 135 , step 9 , loss: -81690.8406: : 10it [00:03,  3.28it/s]\n",
      "epoch 136 , step 9 , loss: -82300.3992: : 10it [00:03,  3.24it/s]\n",
      "epoch 137 , step 9 , loss: -82908.9102: : 10it [00:02,  3.38it/s]\n",
      "epoch 138 , step 9 , loss: -83522.6539: : 10it [00:03,  2.64it/s]\n",
      "epoch 139 , step 9 , loss: -84129.1125: : 10it [00:03,  3.15it/s]\n",
      "epoch 140 , step 9 , loss: -84741.9438: : 10it [00:03,  2.82it/s]\n",
      "epoch 141 , step 9 , loss: -85350.9039: : 10it [00:03,  3.10it/s]\n",
      "epoch 142 , step 9 , loss: -85945.2430: : 10it [00:02,  3.37it/s]\n",
      "epoch 143 , step 9 , loss: -86548.4594: : 10it [00:03,  3.01it/s]\n",
      "epoch 144 , step 9 , loss: -87143.9109: : 10it [00:02,  3.42it/s]\n",
      "epoch 145 , step 9 , loss: -87747.5430: : 10it [00:02,  3.39it/s]\n",
      "epoch 146 , step 9 , loss: -88346.0039: : 10it [00:02,  3.45it/s]\n",
      "epoch 147 , step 9 , loss: -88954.0805: : 10it [00:02,  3.40it/s]\n",
      "epoch 148 , step 9 , loss: -89564.2500: : 10it [00:02,  3.40it/s]\n",
      "epoch 149 , step 9 , loss: -90174.7742: : 10it [00:02,  3.34it/s]\n",
      "epoch 150 , step 9 , loss: -90778.7281: : 10it [00:03,  3.25it/s]\n",
      "epoch 151 , step 9 , loss: -91381.1758: : 10it [00:02,  3.39it/s]\n",
      "epoch 152 , step 9 , loss: -91994.0906: : 10it [00:02,  3.40it/s]\n",
      "epoch 153 , step 9 , loss: -92612.0172: : 10it [00:02,  3.46it/s]\n",
      "epoch 154 , step 9 , loss: -93225.6320: : 10it [00:02,  3.38it/s]\n",
      "epoch 155 , step 9 , loss: -93831.2633: : 10it [00:03,  3.31it/s]\n",
      "epoch 156 , step 9 , loss: -94433.4891: : 10it [00:02,  3.37it/s]\n",
      "epoch 157 , step 9 , loss: -95033.0430: : 10it [00:02,  3.41it/s]\n",
      "epoch 158 , step 9 , loss: -95626.6266: : 10it [00:02,  3.41it/s]\n",
      "epoch 159 , step 9 , loss: -96231.9461: : 10it [00:02,  3.40it/s]\n",
      "epoch 160 , step 9 , loss: -96844.0180: : 10it [00:02,  3.42it/s]\n",
      "epoch 161 , step 9 , loss: -97458.3430: : 10it [00:03,  3.04it/s]\n",
      "epoch 162 , step 9 , loss: -98065.1484: : 10it [00:03,  3.12it/s]\n",
      "epoch 163 , step 9 , loss: -98673.9937: : 10it [00:03,  3.05it/s]\n",
      "epoch 164 , step 9 , loss: -99290.0477: : 10it [00:03,  3.08it/s]\n",
      "epoch 165 , step 9 , loss: -99911.0469: : 10it [00:02,  3.50it/s]\n",
      "epoch 166 , step 9 , loss: -100527.8820: : 10it [00:02,  3.49it/s]\n",
      "epoch 167 , step 9 , loss: -101135.7531: : 10it [00:02,  3.43it/s]\n",
      "epoch 168 , step 9 , loss: -101738.4273: : 10it [00:03,  3.04it/s]\n",
      "epoch 169 , step 9 , loss: -102349.7211: : 10it [00:02,  3.41it/s]\n",
      "epoch 170 , step 9 , loss: -102968.0492: : 10it [00:02,  3.45it/s]\n",
      "epoch 171 , step 9 , loss: -103583.6820: : 10it [00:02,  3.36it/s]\n",
      "epoch 172 , step 9 , loss: -104202.8969: : 10it [00:03,  3.33it/s]\n",
      "epoch 173 , step 9 , loss: -104833.0797: : 10it [00:02,  3.41it/s]\n",
      "epoch 174 , step 9 , loss: -105468.2852: : 10it [00:02,  3.37it/s]\n",
      "epoch 175 , step 9 , loss: -106089.6492: : 10it [00:02,  3.35it/s]\n",
      "epoch 176 , step 9 , loss: -106685.8219: : 10it [00:02,  3.42it/s]\n",
      "epoch 177 , step 9 , loss: -107275.5531: : 10it [00:03,  3.31it/s]\n",
      "epoch 178 , step 9 , loss: -107867.7445: : 10it [00:03,  3.28it/s]\n",
      "epoch 179 , step 9 , loss: -108488.0523: : 10it [00:03,  3.15it/s]\n",
      "epoch 180 , step 9 , loss: -109115.6281: : 10it [00:03,  3.00it/s]\n",
      "epoch 181 , step 9 , loss: -109741.3141: : 10it [00:03,  2.77it/s]\n",
      "epoch 182 , step 9 , loss: -110369.1555: : 10it [00:02,  3.36it/s]\n",
      "epoch 183 , step 9 , loss: -110974.5359: : 10it [00:02,  3.44it/s]\n",
      "epoch 184 , step 9 , loss: -111568.0781: : 10it [00:02,  3.42it/s]\n",
      "epoch 185 , step 9 , loss: -112166.1672: : 10it [00:03,  3.05it/s]\n",
      "epoch 186 , step 9 , loss: -112762.5555: : 10it [00:02,  3.35it/s]\n",
      "epoch 187 , step 9 , loss: -113367.6680: : 10it [00:03,  3.32it/s]\n",
      "epoch 188 , step 9 , loss: -113972.4477: : 10it [00:02,  3.38it/s]\n",
      "epoch 189 , step 9 , loss: -114572.7437: : 10it [00:02,  3.36it/s]\n",
      "epoch 190 , step 9 , loss: -115166.9141: : 10it [00:02,  3.40it/s]\n",
      "epoch 191 , step 9 , loss: -115768.0914: : 10it [00:02,  3.46it/s]\n",
      "epoch 192 , step 9 , loss: -116378.0813: : 10it [00:02,  3.45it/s]\n",
      "epoch 193 , step 9 , loss: -116980.5922: : 10it [00:02,  3.35it/s]\n",
      "epoch 194 , step 9 , loss: -117582.8234: : 10it [00:02,  3.42it/s]\n",
      "epoch 195 , step 9 , loss: -118183.5617: : 10it [00:03,  3.28it/s]\n",
      "epoch 196 , step 9 , loss: -118789.9203: : 10it [00:02,  3.42it/s]\n",
      "epoch 197 , step 9 , loss: -119396.2961: : 10it [00:02,  3.41it/s]\n",
      "epoch 198 , step 9 , loss: -119993.9977: : 10it [00:02,  3.48it/s]\n",
      "epoch 199 , step 9 , loss: -120594.8516: : 10it [00:02,  3.46it/s]\n",
      "epoch 200 , step 9 , loss: -121194.1680: : 10it [00:02,  3.43it/s]\n",
      "epoch 201 , step 9 , loss: -121805.6844: : 10it [00:03,  3.20it/s]\n",
      "epoch 202 , step 9 , loss: -122427.7758: : 10it [00:02,  3.43it/s]\n",
      "epoch 203 , step 9 , loss: -123021.9664: : 10it [00:02,  3.43it/s]\n",
      "epoch 204 , step 9 , loss: -123607.7297: : 10it [00:02,  3.38it/s]\n",
      "epoch 205 , step 9 , loss: -124199.1367: : 10it [00:02,  3.35it/s]\n",
      "epoch 206 , step 9 , loss: -124784.6773: : 10it [00:02,  3.42it/s]\n",
      "epoch 207 , step 9 , loss: -125377.1633: : 10it [00:02,  3.41it/s]\n",
      "epoch 208 , step 9 , loss: -125971.9047: : 10it [00:02,  3.40it/s]\n",
      "epoch 209 , step 9 , loss: -126555.0680: : 10it [00:02,  3.46it/s]\n",
      "epoch 210 , step 9 , loss: -127169.0203: : 10it [00:02,  3.37it/s]\n",
      "epoch 211 , step 9 , loss: -127785.9047: : 10it [00:02,  3.35it/s]\n",
      "epoch 212 , step 9 , loss: -128389.7875: : 10it [00:02,  3.35it/s]\n",
      "epoch 213 , step 9 , loss: -128993.7672: : 10it [00:02,  3.45it/s]\n",
      "epoch 214 , step 9 , loss: -129605.0648: : 10it [00:02,  3.34it/s]\n",
      "epoch 215 , step 9 , loss: -130206.3086: : 10it [00:02,  3.45it/s]\n",
      "epoch 216 , step 9 , loss: -130826.3602: : 10it [00:02,  3.44it/s]\n",
      "epoch 217 , step 9 , loss: -131448.3719: : 10it [00:03,  3.32it/s]\n",
      "epoch 218 , step 9 , loss: -132056.6156: : 10it [00:02,  3.45it/s]\n",
      "epoch 219 , step 9 , loss: -132664.3969: : 10it [00:02,  3.39it/s]\n",
      "epoch 220 , step 9 , loss: -133280.2047: : 10it [00:03,  3.19it/s]\n",
      "epoch 221 , step 9 , loss: -133910.4125: : 10it [00:03,  3.17it/s]\n",
      "epoch 222 , step 9 , loss: -134534.5328: : 10it [00:03,  3.21it/s]\n",
      "epoch 223 , step 9 , loss: -135154.9656: : 10it [00:03,  3.10it/s]\n",
      "epoch 224 , step 9 , loss: -135775.4469: : 10it [00:02,  3.44it/s]\n",
      "epoch 225 , step 9 , loss: -136408.3828: : 10it [00:02,  3.45it/s]\n",
      "epoch 226 , step 9 , loss: -137036.0312: : 10it [00:02,  3.42it/s]\n",
      "epoch 227 , step 9 , loss: -137637.0438: : 10it [00:02,  3.42it/s]\n",
      "epoch 228 , step 9 , loss: -138232.8422: : 10it [00:02,  3.37it/s]\n",
      "epoch 229 , step 9 , loss: -138814.0562: : 10it [00:02,  3.44it/s]\n",
      "epoch 230 , step 9 , loss: -139414.0328: : 10it [00:02,  3.43it/s]\n",
      "epoch 231 , step 9 , loss: -140058.0484: : 10it [00:02,  3.43it/s]\n",
      "epoch 232 , step 9 , loss: -140671.6344: : 10it [00:02,  3.38it/s]\n",
      "epoch 233 , step 9 , loss: -141239.6172: : 10it [00:02,  3.46it/s]\n",
      "epoch 234 , step 9 , loss: -141810.6953: : 10it [00:02,  3.46it/s]\n",
      "epoch 235 , step 9 , loss: -142366.6797: : 10it [00:02,  3.47it/s]\n",
      "epoch 236 , step 9 , loss: -142940.7609: : 10it [00:02,  3.36it/s]\n",
      "epoch 237 , step 9 , loss: -143546.2672: : 10it [00:02,  3.37it/s]\n",
      "epoch 238 , step 9 , loss: -144145.1812: : 10it [00:02,  3.41it/s]\n",
      "epoch 239 , step 9 , loss: -144728.2766: : 10it [00:02,  3.45it/s]\n",
      "epoch 240 , step 9 , loss: -145339.9406: : 10it [00:02,  3.45it/s]\n",
      "epoch 241 , step 9 , loss: -145966.6547: : 10it [00:02,  3.45it/s]\n",
      "epoch 242 , step 9 , loss: -146598.4469: : 10it [00:02,  3.38it/s]\n",
      "epoch 243 , step 9 , loss: -147227.9125: : 10it [00:02,  3.47it/s]\n",
      "epoch 244 , step 9 , loss: -147870.3156: : 10it [00:02,  3.40it/s]\n",
      "epoch 245 , step 9 , loss: -148498.3969: : 10it [00:02,  3.46it/s]\n",
      "epoch 246 , step 9 , loss: -149117.5031: : 10it [00:02,  3.41it/s]\n",
      "epoch 247 , step 9 , loss: -149726.9250: : 10it [00:02,  3.40it/s]\n",
      "epoch 248 , step 9 , loss: -150298.8266: : 10it [00:02,  3.42it/s]\n",
      "epoch 249 , step 9 , loss: -150870.9734: : 10it [00:02,  3.48it/s]\n",
      "epoch 250 , step 9 , loss: -151442.6562: : 10it [00:02,  3.45it/s]\n",
      "epoch 251 , step 9 , loss: -152022.0281: : 10it [00:02,  3.50it/s]\n",
      "epoch 252 , step 9 , loss: -152609.2234: : 10it [00:02,  3.44it/s]\n",
      "epoch 253 , step 9 , loss: -153186.9781: : 10it [00:02,  3.42it/s]\n",
      "epoch 254 , step 9 , loss: -153787.1938: : 10it [00:02,  3.42it/s]\n",
      "epoch 255 , step 9 , loss: -154384.4328: : 10it [00:03,  3.17it/s]\n",
      "epoch 256 , step 9 , loss: -154966.5781: : 10it [00:02,  3.49it/s]\n",
      "epoch 257 , step 9 , loss: -155539.3859: : 10it [00:02,  3.37it/s]\n",
      "epoch 258 , step 9 , loss: -156137.7563: : 10it [00:02,  3.40it/s]\n",
      "epoch 259 , step 9 , loss: -156754.6406: : 10it [00:02,  3.36it/s]\n",
      "epoch 260 , step 9 , loss: -157372.3500: : 10it [00:02,  3.37it/s]\n",
      "epoch 261 , step 9 , loss: -157989.5266: : 10it [00:03,  3.21it/s]\n",
      "epoch 262 , step 9 , loss: -158617.2797: : 10it [00:03,  3.02it/s]\n",
      "epoch 263 , step 9 , loss: -159243.5266: : 10it [00:03,  3.08it/s]\n",
      "epoch 264 , step 9 , loss: -159845.6187: : 10it [00:03,  3.07it/s]\n",
      "epoch 265 , step 9 , loss: -160449.3766: : 10it [00:03,  3.33it/s]\n",
      "epoch 266 , step 9 , loss: -161048.1531: : 10it [00:02,  3.39it/s]\n",
      "epoch 267 , step 9 , loss: -161664.3172: : 10it [00:02,  3.39it/s]\n",
      "epoch 268 , step 9 , loss: -162289.2687: : 10it [00:02,  3.43it/s]\n",
      "epoch 269 , step 9 , loss: -162905.9047: : 10it [00:02,  3.41it/s]\n",
      "epoch 270 , step 9 , loss: -163487.9937: : 10it [00:03,  3.28it/s]\n",
      "epoch 271 , step 9 , loss: -164074.9312: : 10it [00:02,  3.45it/s]\n",
      "epoch 272 , step 9 , loss: -164654.0312: : 10it [00:02,  3.34it/s]\n",
      "epoch 273 , step 9 , loss: -165237.7281: : 10it [00:02,  3.39it/s]\n",
      "epoch 274 , step 9 , loss: -165825.2031: : 10it [00:03,  3.28it/s]\n",
      "epoch 275 , step 9 , loss: -166438.0391: : 10it [00:03,  3.30it/s]\n",
      "epoch 276 , step 9 , loss: -167048.7500: : 10it [00:03,  3.12it/s]\n",
      "epoch 277 , step 9 , loss: -167644.6984: : 10it [00:02,  3.40it/s]\n",
      "epoch 278 , step 9 , loss: -168234.9312: : 10it [00:02,  3.39it/s]\n",
      "epoch 279 , step 9 , loss: -168832.8344: : 10it [00:03,  3.30it/s]\n",
      "epoch 280 , step 9 , loss: -169475.3422: : 10it [00:02,  3.45it/s]\n",
      "epoch 281 , step 9 , loss: -170122.2594: : 10it [00:02,  3.42it/s]\n",
      "epoch 282 , step 9 , loss: -170739.7516: : 10it [00:03,  3.32it/s]\n",
      "epoch 283 , step 9 , loss: -171344.1703: : 10it [00:02,  3.36it/s]\n",
      "epoch 284 , step 9 , loss: -171954.5734: : 10it [00:02,  3.42it/s]\n",
      "epoch 285 , step 9 , loss: -172549.2359: : 10it [00:02,  3.35it/s]\n",
      "epoch 286 , step 9 , loss: -173170.2016: : 10it [00:02,  3.42it/s]\n",
      "epoch 287 , step 9 , loss: -173784.6750: : 10it [00:03,  3.31it/s]\n",
      "epoch 288 , step 9 , loss: -174357.5969: : 10it [00:02,  3.35it/s]\n",
      "epoch 289 , step 9 , loss: -174931.7391: : 10it [00:02,  3.43it/s]\n",
      "epoch 290 , step 9 , loss: -175567.5594: : 10it [00:02,  3.34it/s]\n",
      "epoch 291 , step 9 , loss: -176184.6938: : 10it [00:02,  3.41it/s]\n",
      "epoch 292 , step 9 , loss: -176757.8656: : 10it [00:02,  3.43it/s]\n",
      "epoch 293 , step 9 , loss: -177308.2625: : 10it [00:02,  3.40it/s]\n",
      "epoch 294 , step 9 , loss: -177860.8000: : 10it [00:02,  3.40it/s]\n",
      "epoch 295 , step 9 , loss: -178448.4062: : 10it [00:02,  3.43it/s]\n",
      "epoch 296 , step 9 , loss: -179031.6156: : 10it [00:02,  3.43it/s]\n",
      "epoch 297 , step 9 , loss: -179632.7000: : 10it [00:02,  3.37it/s]\n",
      "epoch 298 , step 9 , loss: -180251.4141: : 10it [00:02,  3.45it/s]\n",
      "epoch 299 , step 9 , loss: -180824.3125: : 10it [00:02,  3.34it/s]\n",
      "epoch 300 , step 9 , loss: -181420.9781: : 10it [00:02,  3.43it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "for epoch in range(hparams['epochs']):\n",
    "    tqdm_ = tqdm(enumerate(loader))\n",
    "    total_loss = 0\n",
    "\n",
    "    for step,x in tqdm_:\n",
    "        model.zero_grad()\n",
    "        loss = model.neg_log_likelihood(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        tqdm_.set_description(\"epoch {:d} , step {:d} , loss: {:.4f}\".format(epoch+1, step, total_loss/(step+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:tensor([[3, 3, 3,  ..., 3, 3, 3],\n        [3, 3, 3,  ..., 3, 3, 3],\n        [3, 3, 3,  ..., 3, 3, 3],\n        ...,\n        [3, 3, 3,  ..., 3, 3, 3],\n        [3, 3, 3,  ..., 3, 3, 3],\n        [3, 3, 3,  ..., 3, 3, 3]], device='cuda:0')\n Ground Truth:tensor([[ 3,  3,  3,  ...,  2,  2,  2],\n        [ 3,  3,  3,  ...,  2,  2,  2],\n        [14, 15, 15,  ...,  2,  2,  2],\n        ...,\n        [ 3,  3,  3,  ...,  2,  2,  2],\n        [ 8,  9,  9,  ...,  2,  2,  2],\n        [16, 17, 17,  ...,  2,  2,  2]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    record = next(iter(loader))\n",
    "    _, tag_seq = model(record['token'])\n",
    "    print(\"Prediction:{}\\n Ground Truth:{}\".format(tag_seq, record['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['B-M',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "predict(['窦志成获奖'],model,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}