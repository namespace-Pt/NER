{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnconda048fc75fe4ee43f1aa97608c8881ebba",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.base_model import BiLSTM_CRF\n",
    "from utils.utils import prepare, predict, train, evaluate\n",
    "\n",
    "hparams = {\n",
    "    'path':'data/data.txt',\n",
    "    'epochs': 100,\n",
    "    'batch_size': 100,\n",
    "    'embedding_dim': 300,\n",
    "    'hidden_dim': 256,\n",
    "    'device':'cuda:0',\n",
    "    'seq_length': 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_dict, loaders = prepare(hparams)\n",
    "hparams['vocab_size'] = len(attr_dict['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BiLSTM_CRF(hparams, attr_dict['tag2idx']).to(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "epoch 1 , step 8 , loss: 528.7582: : 9it [00:02,  3.29it/s]\n",
      "{'weighted_f1': 0.688, 'micro_f1': 0.6996, 'macro_f1': 0.0539}\n",
      "epoch 2 , step 8 , loss: 303.9706: : 9it [00:02,  3.61it/s]\n",
      "{'weighted_f1': 0.6884, 'micro_f1': 0.7019, 'macro_f1': 0.0597}\n",
      "epoch 3 , step 8 , loss: 263.9059: : 9it [00:02,  3.49it/s]\n",
      "{'weighted_f1': 0.7759, 'micro_f1': 0.7678, 'macro_f1': 0.1107}\n",
      "epoch 4 , step 8 , loss: 207.6865: : 9it [00:02,  3.27it/s]\n",
      "{'weighted_f1': 0.8096, 'micro_f1': 0.835, 'macro_f1': 0.1096}\n",
      "epoch 5 , step 8 , loss: 176.3083: : 9it [00:02,  3.23it/s]\n",
      "{'weighted_f1': 0.8253, 'micro_f1': 0.8394, 'macro_f1': 0.1385}\n",
      "epoch 6 , step 8 , loss: 157.1234: : 9it [00:02,  3.69it/s]\n",
      "{'weighted_f1': 0.8367, 'micro_f1': 0.8556, 'macro_f1': 0.1588}\n",
      "epoch 7 , step 8 , loss: 145.0483: : 9it [00:02,  3.44it/s]\n",
      "{'weighted_f1': 0.8461, 'micro_f1': 0.8595, 'macro_f1': 0.1808}\n",
      "epoch 8 , step 8 , loss: 134.5387: : 9it [00:02,  3.80it/s]\n",
      "{'weighted_f1': 0.8545, 'micro_f1': 0.8679, 'macro_f1': 0.1999}\n",
      "epoch 9 , step 8 , loss: 125.4033: : 9it [00:02,  3.47it/s]\n",
      "{'weighted_f1': 0.8638, 'micro_f1': 0.8749, 'macro_f1': 0.2291}\n",
      "epoch 10 , step 8 , loss: 116.9354: : 9it [00:02,  3.45it/s]\n",
      "{'weighted_f1': 0.8707, 'micro_f1': 0.8813, 'macro_f1': 0.2501}\n",
      "epoch 11 , step 8 , loss: 108.6631: : 9it [00:02,  3.87it/s]\n",
      "{'weighted_f1': 0.8769, 'micro_f1': 0.8864, 'macro_f1': 0.2738}\n",
      "epoch 12 , step 8 , loss: 100.9117: : 9it [00:02,  3.30it/s]\n",
      "{'weighted_f1': 0.8841, 'micro_f1': 0.893, 'macro_f1': 0.2968}\n",
      "epoch 13 , step 8 , loss: 93.0319: : 9it [00:02,  3.46it/s]\n",
      "{'weighted_f1': 0.8919, 'micro_f1': 0.8999, 'macro_f1': 0.3292}\n",
      "epoch 14 , step 8 , loss: 85.5690: : 9it [00:02,  3.84it/s]\n",
      "{'weighted_f1': 0.9001, 'micro_f1': 0.9081, 'macro_f1': 0.3633}\n",
      "epoch 15 , step 8 , loss: 78.9497: : 9it [00:02,  3.50it/s]\n",
      "{'weighted_f1': 0.905, 'micro_f1': 0.913, 'macro_f1': 0.3882}\n",
      "epoch 16 , step 8 , loss: 73.5022: : 9it [00:02,  3.78it/s]\n",
      "{'weighted_f1': 0.911, 'micro_f1': 0.9159, 'macro_f1': 0.4118}\n",
      "epoch 17 , step 8 , loss: 66.9043: : 9it [00:02,  3.46it/s]\n",
      "{'weighted_f1': 0.9164, 'micro_f1': 0.9203, 'macro_f1': 0.4434}\n",
      "epoch 18 , step 8 , loss: 62.2896: : 9it [00:02,  3.75it/s]\n",
      "{'weighted_f1': 0.9171, 'micro_f1': 0.9199, 'macro_f1': 0.45}\n",
      "epoch 19 , step 8 , loss: 56.8365: : 9it [00:02,  3.69it/s]\n",
      "{'weighted_f1': 0.9227, 'micro_f1': 0.9259, 'macro_f1': 0.4723}\n",
      "epoch 20 , step 8 , loss: 52.2100: : 9it [00:02,  3.83it/s]\n",
      "{'weighted_f1': 0.9259, 'micro_f1': 0.9291, 'macro_f1': 0.4865}\n",
      "epoch 21 , step 8 , loss: 48.1278: : 9it [00:02,  3.87it/s]\n",
      "{'weighted_f1': 0.9294, 'micro_f1': 0.9329, 'macro_f1': 0.5038}\n",
      "epoch 22 , step 8 , loss: 44.4284: : 9it [00:02,  3.59it/s]\n",
      "{'weighted_f1': 0.9312, 'micro_f1': 0.9342, 'macro_f1': 0.5189}\n",
      "epoch 23 , step 8 , loss: 41.1177: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.9332, 'micro_f1': 0.9362, 'macro_f1': 0.5278}\n",
      "epoch 24 , step 8 , loss: 38.1810: : 9it [00:02,  3.44it/s]\n",
      "{'weighted_f1': 0.9351, 'micro_f1': 0.9379, 'macro_f1': 0.539}\n",
      "epoch 25 , step 8 , loss: 36.0277: : 9it [00:02,  3.75it/s]\n",
      "{'weighted_f1': 0.9371, 'micro_f1': 0.939, 'macro_f1': 0.5592}\n",
      "epoch 26 , step 8 , loss: 34.4369: : 9it [00:02,  3.66it/s]\n",
      "{'weighted_f1': 0.9372, 'micro_f1': 0.94, 'macro_f1': 0.5582}\n",
      "epoch 27 , step 8 , loss: 31.9717: : 9it [00:02,  3.62it/s]\n",
      "{'weighted_f1': 0.9386, 'micro_f1': 0.9407, 'macro_f1': 0.5715}\n",
      "epoch 28 , step 8 , loss: 30.0162: : 9it [00:02,  3.49it/s]\n",
      "{'weighted_f1': 0.9406, 'micro_f1': 0.9426, 'macro_f1': 0.5911}\n",
      "epoch 29 , step 8 , loss: 28.5640: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.9395, 'micro_f1': 0.9406, 'macro_f1': 0.5927}\n",
      "epoch 30 , step 8 , loss: 28.2783: : 9it [00:02,  3.45it/s]\n",
      "{'weighted_f1': 0.9426, 'micro_f1': 0.9437, 'macro_f1': 0.5987}\n",
      "epoch 31 , step 8 , loss: 26.0867: : 9it [00:02,  3.78it/s]\n",
      "{'weighted_f1': 0.9439, 'micro_f1': 0.9456, 'macro_f1': 0.6121}\n",
      "epoch 32 , step 8 , loss: 24.3128: : 9it [00:02,  3.73it/s]\n",
      "{'weighted_f1': 0.9447, 'micro_f1': 0.9464, 'macro_f1': 0.6274}\n",
      "epoch 33 , step 8 , loss: 22.7321: : 9it [00:02,  3.30it/s]\n",
      "{'weighted_f1': 0.9459, 'micro_f1': 0.9474, 'macro_f1': 0.6372}\n",
      "epoch 34 , step 8 , loss: 21.2928: : 9it [00:02,  3.45it/s]\n",
      "{'weighted_f1': 0.9459, 'micro_f1': 0.9474, 'macro_f1': 0.6417}\n",
      "epoch 35 , step 8 , loss: 20.1278: : 9it [00:02,  3.74it/s]\n",
      "{'weighted_f1': 0.9462, 'micro_f1': 0.9478, 'macro_f1': 0.6505}\n",
      "epoch 36 , step 8 , loss: 19.0672: : 9it [00:02,  3.86it/s]\n",
      "{'weighted_f1': 0.9472, 'micro_f1': 0.9488, 'macro_f1': 0.6573}\n",
      "epoch 37 , step 8 , loss: 18.0954: : 9it [00:02,  3.48it/s]\n",
      "{'weighted_f1': 0.9474, 'micro_f1': 0.9485, 'macro_f1': 0.6568}\n",
      "epoch 38 , step 8 , loss: 17.1926: : 9it [00:02,  3.77it/s]\n",
      "{'weighted_f1': 0.9473, 'micro_f1': 0.9481, 'macro_f1': 0.662}\n",
      "epoch 39 , step 8 , loss: 16.3284: : 9it [00:02,  3.50it/s]\n",
      "{'weighted_f1': 0.9475, 'micro_f1': 0.9485, 'macro_f1': 0.6767}\n",
      "epoch 40 , step 8 , loss: 15.5485: : 9it [00:02,  3.77it/s]\n",
      "{'weighted_f1': 0.9488, 'micro_f1': 0.9499, 'macro_f1': 0.6797}\n",
      "epoch 41 , step 8 , loss: 14.8299: : 9it [00:02,  3.73it/s]\n",
      "{'weighted_f1': 0.9476, 'micro_f1': 0.9493, 'macro_f1': 0.67}\n",
      "epoch 42 , step 8 , loss: 14.1939: : 9it [00:02,  3.30it/s]\n",
      "{'weighted_f1': 0.9487, 'micro_f1': 0.9496, 'macro_f1': 0.6827}\n",
      "epoch 43 , step 8 , loss: 13.5246: : 9it [00:02,  3.27it/s]\n",
      "{'weighted_f1': 0.9489, 'micro_f1': 0.9497, 'macro_f1': 0.6945}\n",
      "epoch 44 , step 8 , loss: 12.9505: : 9it [00:02,  3.30it/s]\n",
      "{'weighted_f1': 0.949, 'micro_f1': 0.9498, 'macro_f1': 0.6987}\n",
      "epoch 45 , step 8 , loss: 12.3056: : 9it [00:02,  3.74it/s]\n",
      "{'weighted_f1': 0.9489, 'micro_f1': 0.9497, 'macro_f1': 0.7007}\n",
      "epoch 46 , step 8 , loss: 11.8227: : 9it [00:02,  3.52it/s]\n",
      "{'weighted_f1': 0.9511, 'micro_f1': 0.9524, 'macro_f1': 0.7066}\n",
      "epoch 47 , step 8 , loss: 11.3344: : 9it [00:02,  3.78it/s]\n",
      "{'weighted_f1': 0.95, 'micro_f1': 0.951, 'macro_f1': 0.7068}\n",
      "epoch 48 , step 8 , loss: 10.9114: : 9it [00:02,  3.41it/s]\n",
      "{'weighted_f1': 0.9496, 'micro_f1': 0.9503, 'macro_f1': 0.7066}\n",
      "epoch 49 , step 8 , loss: 10.4894: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.9498, 'micro_f1': 0.9508, 'macro_f1': 0.7044}\n",
      "epoch 50 , step 8 , loss: 10.1227: : 9it [00:02,  3.51it/s]\n",
      "{'weighted_f1': 0.951, 'micro_f1': 0.9521, 'macro_f1': 0.7134}\n",
      "epoch 51 , step 8 , loss: 9.6477: : 9it [00:02,  3.45it/s]\n",
      "{'weighted_f1': 0.9501, 'micro_f1': 0.9511, 'macro_f1': 0.7085}\n",
      "epoch 52 , step 8 , loss: 9.3072: : 9it [00:02,  3.49it/s]\n",
      "{'weighted_f1': 0.951, 'micro_f1': 0.9515, 'macro_f1': 0.712}\n",
      "epoch 53 , step 8 , loss: 8.9876: : 9it [00:02,  3.80it/s]\n",
      "{'weighted_f1': 0.9495, 'micro_f1': 0.9501, 'macro_f1': 0.7084}\n",
      "epoch 54 , step 8 , loss: 8.7136: : 9it [00:02,  3.82it/s]\n",
      "{'weighted_f1': 0.9507, 'micro_f1': 0.9514, 'macro_f1': 0.7167}\n",
      "epoch 55 , step 8 , loss: 8.4370: : 9it [00:02,  3.74it/s]\n",
      "{'weighted_f1': 0.9503, 'micro_f1': 0.9508, 'macro_f1': 0.7172}\n",
      "epoch 56 , step 8 , loss: 8.0729: : 9it [00:02,  3.49it/s]\n",
      "{'weighted_f1': 0.9511, 'micro_f1': 0.9516, 'macro_f1': 0.7242}\n",
      "epoch 57 , step 8 , loss: 7.6612: : 9it [00:02,  3.70it/s]\n",
      "{'weighted_f1': 0.9498, 'micro_f1': 0.9507, 'macro_f1': 0.7166}\n",
      "epoch 58 , step 8 , loss: 7.3809: : 9it [00:02,  3.74it/s]\n",
      "{'weighted_f1': 0.9516, 'micro_f1': 0.952, 'macro_f1': 0.7289}\n",
      "epoch 59 , step 8 , loss: 7.1618: : 9it [00:02,  3.81it/s]\n",
      "{'weighted_f1': 0.9504, 'micro_f1': 0.9514, 'macro_f1': 0.7197}\n",
      "epoch 60 , step 8 , loss: 6.9383: : 9it [00:02,  3.50it/s]\n",
      "{'weighted_f1': 0.9513, 'micro_f1': 0.9519, 'macro_f1': 0.7239}\n",
      "epoch 61 , step 8 , loss: 6.6978: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.952, 'micro_f1': 0.9527, 'macro_f1': 0.731}\n",
      "epoch 62 , step 8 , loss: 6.4503: : 9it [00:02,  3.32it/s]\n",
      "{'weighted_f1': 0.9513, 'micro_f1': 0.9522, 'macro_f1': 0.728}\n",
      "epoch 63 , step 8 , loss: 6.2654: : 9it [00:02,  3.23it/s]\n",
      "{'weighted_f1': 0.9514, 'micro_f1': 0.952, 'macro_f1': 0.7272}\n",
      "epoch 64 , step 8 , loss: 6.0826: : 9it [00:02,  3.30it/s]\n",
      "{'weighted_f1': 0.9509, 'micro_f1': 0.951, 'macro_f1': 0.7239}\n",
      "epoch 65 , step 8 , loss: 5.9086: : 9it [00:02,  3.34it/s]\n",
      "{'weighted_f1': 0.9506, 'micro_f1': 0.9515, 'macro_f1': 0.7238}\n",
      "epoch 66 , step 8 , loss: 5.7963: : 9it [00:02,  3.44it/s]\n",
      "{'weighted_f1': 0.9512, 'micro_f1': 0.9521, 'macro_f1': 0.731}\n",
      "epoch 67 , step 8 , loss: 5.6644: : 9it [00:02,  3.50it/s]\n",
      "{'weighted_f1': 0.951, 'micro_f1': 0.9513, 'macro_f1': 0.7276}\n",
      "epoch 68 , step 8 , loss: 5.5405: : 9it [00:02,  3.24it/s]\n",
      "{'weighted_f1': 0.9504, 'micro_f1': 0.95, 'macro_f1': 0.7389}\n",
      "epoch 69 , step 8 , loss: 5.3960: : 9it [00:02,  3.30it/s]\n",
      "{'weighted_f1': 0.951, 'micro_f1': 0.9509, 'macro_f1': 0.7352}\n",
      "epoch 70 , step 8 , loss: 5.2365: : 9it [00:02,  3.20it/s]\n",
      "{'weighted_f1': 0.9504, 'micro_f1': 0.9509, 'macro_f1': 0.7253}\n",
      "epoch 71 , step 8 , loss: 5.0315: : 9it [00:02,  3.31it/s]\n",
      "{'weighted_f1': 0.9507, 'micro_f1': 0.9508, 'macro_f1': 0.7311}\n",
      "epoch 72 , step 8 , loss: 5.4671: : 9it [00:02,  3.14it/s]\n",
      "{'weighted_f1': 0.9508, 'micro_f1': 0.9513, 'macro_f1': 0.7289}\n",
      "epoch 73 , step 8 , loss: 5.5796: : 9it [00:02,  3.42it/s]\n",
      "{'weighted_f1': 0.9536, 'micro_f1': 0.9544, 'macro_f1': 0.7412}\n",
      "epoch 74 , step 8 , loss: 5.8469: : 9it [00:02,  3.36it/s]\n",
      "{'weighted_f1': 0.9515, 'micro_f1': 0.9525, 'macro_f1': 0.7389}\n",
      "epoch 75 , step 8 , loss: 5.4872: : 9it [00:02,  3.20it/s]\n",
      "{'weighted_f1': 0.9514, 'micro_f1': 0.9519, 'macro_f1': 0.738}\n",
      "epoch 76 , step 8 , loss: 5.2129: : 9it [00:02,  3.41it/s]\n",
      "{'weighted_f1': 0.9516, 'micro_f1': 0.9513, 'macro_f1': 0.7453}\n",
      "epoch 77 , step 8 , loss: 4.8589: : 9it [00:02,  3.48it/s]\n",
      "{'weighted_f1': 0.9496, 'micro_f1': 0.95, 'macro_f1': 0.7326}\n",
      "epoch 78 , step 8 , loss: 5.5405: : 9it [00:02,  3.42it/s]\n",
      "{'weighted_f1': 0.9494, 'micro_f1': 0.9491, 'macro_f1': 0.7234}\n",
      "epoch 79 , step 8 , loss: 5.4770: : 9it [00:02,  3.82it/s]\n",
      "{'weighted_f1': 0.9516, 'micro_f1': 0.9517, 'macro_f1': 0.7379}\n",
      "epoch 80 , step 8 , loss: 5.0595: : 9it [00:02,  3.69it/s]\n",
      "{'weighted_f1': 0.952, 'micro_f1': 0.9524, 'macro_f1': 0.7299}\n",
      "epoch 81 , step 8 , loss: 4.5735: : 9it [00:02,  3.49it/s]\n",
      "{'weighted_f1': 0.9536, 'micro_f1': 0.9543, 'macro_f1': 0.7357}\n",
      "epoch 82 , step 8 , loss: 4.1952: : 9it [00:02,  3.44it/s]\n",
      "{'weighted_f1': 0.9528, 'micro_f1': 0.9536, 'macro_f1': 0.7375}\n",
      "epoch 83 , step 8 , loss: 4.0068: : 9it [00:02,  3.64it/s]\n",
      "{'weighted_f1': 0.9528, 'micro_f1': 0.9539, 'macro_f1': 0.7323}\n",
      "epoch 84 , step 8 , loss: 3.8101: : 9it [00:02,  3.72it/s]\n",
      "{'weighted_f1': 0.9525, 'micro_f1': 0.953, 'macro_f1': 0.7401}\n",
      "epoch 85 , step 8 , loss: 3.6650: : 9it [00:02,  3.53it/s]\n",
      "{'weighted_f1': 0.9523, 'micro_f1': 0.9527, 'macro_f1': 0.7358}\n",
      "epoch 86 , step 8 , loss: 3.5628: : 9it [00:02,  3.84it/s]\n",
      "{'weighted_f1': 0.9534, 'micro_f1': 0.9541, 'macro_f1': 0.7409}\n",
      "epoch 87 , step 8 , loss: 3.4090: : 9it [00:02,  3.72it/s]\n",
      "{'weighted_f1': 0.9527, 'micro_f1': 0.9535, 'macro_f1': 0.7362}\n",
      "epoch 88 , step 8 , loss: 3.3093: : 9it [00:02,  3.75it/s]\n",
      "{'weighted_f1': 0.9519, 'micro_f1': 0.9527, 'macro_f1': 0.7331}\n",
      "epoch 89 , step 8 , loss: 3.2225: : 9it [00:02,  3.48it/s]\n",
      "{'weighted_f1': 0.952, 'micro_f1': 0.9524, 'macro_f1': 0.7361}\n",
      "epoch 90 , step 8 , loss: 3.1496: : 9it [00:02,  3.56it/s]\n",
      "{'weighted_f1': 0.9523, 'micro_f1': 0.9528, 'macro_f1': 0.7375}\n",
      "epoch 91 , step 8 , loss: 3.0687: : 9it [00:02,  3.37it/s]\n",
      "{'weighted_f1': 0.9519, 'micro_f1': 0.9527, 'macro_f1': 0.7383}\n",
      "epoch 92 , step 8 , loss: 3.0293: : 9it [00:02,  3.83it/s]\n",
      "{'weighted_f1': 0.9515, 'micro_f1': 0.9526, 'macro_f1': 0.7312}\n",
      "epoch 93 , step 8 , loss: 2.9303: : 9it [00:02,  3.72it/s]\n",
      "{'weighted_f1': 0.9517, 'micro_f1': 0.9523, 'macro_f1': 0.7416}\n",
      "epoch 94 , step 8 , loss: 2.8703: : 9it [00:02,  3.75it/s]\n",
      "{'weighted_f1': 0.9531, 'micro_f1': 0.9537, 'macro_f1': 0.7459}\n",
      "epoch 95 , step 8 , loss: 2.7942: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.9519, 'micro_f1': 0.9527, 'macro_f1': 0.7413}\n",
      "epoch 96 , step 8 , loss: 2.7336: : 9it [00:02,  3.43it/s]\n",
      "{'weighted_f1': 0.9515, 'micro_f1': 0.9523, 'macro_f1': 0.7344}\n",
      "epoch 97 , step 8 , loss: 2.7212: : 9it [00:02,  3.40it/s]\n",
      "{'weighted_f1': 0.9518, 'micro_f1': 0.9524, 'macro_f1': 0.7419}\n",
      "epoch 98 , step 8 , loss: 2.6161: : 9it [00:02,  3.75it/s]\n",
      "{'weighted_f1': 0.9516, 'micro_f1': 0.9522, 'macro_f1': 0.7389}\n",
      "epoch 99 , step 8 , loss: 2.5728: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.952, 'micro_f1': 0.9525, 'macro_f1': 0.7385}\n",
      "epoch 100 , step 8 , loss: 2.5313: : 9it [00:02,  3.79it/s]\n",
      "{'weighted_f1': 0.9514, 'micro_f1': 0.9522, 'macro_f1': 0.7333}\n"
     ]
    }
   ],
   "source": [
    "base_model = train(hparams, base_model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           2       1.00      1.00      1.00     17414\n           3       0.33      0.09      0.14        11\n           4       0.92      0.35      0.50       136\n           5       0.50      0.60      0.55        35\n           6       0.62      0.65      0.63       451\n           7       0.85      0.85      0.85       177\n           8       0.91      0.90      0.91       777\n           9       0.88      0.78      0.82        27\n          10       0.90      0.86      0.88       114\n          11       0.83      0.66      0.73        61\n          12       0.81      0.71      0.75       321\n          13       0.93      0.92      0.93       180\n          14       0.82      0.93      0.87       316\n          15       0.71      0.55      0.62        67\n          16       0.74      0.73      0.73       495\n          17       0.83      0.82      0.82       181\n          18       0.82      0.80      0.81       371\n          19       0.50      0.50      0.50        18\n          20       0.70      0.91      0.79       178\n          21       0.89      0.91      0.90      4014\n\n    accuracy                           0.95     25344\n   macro avg       0.78      0.73      0.74     25344\nweighted avg       0.95      0.95      0.95     25344\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'weighted_f1': 0.9517, 'micro_f1': 0.9525, 'macro_f1': 0.7378}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "evaluate(base_model, loaders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['B-department',\n",
       "  'I-department',\n",
       "  'I-department',\n",
       "  'I-department',\n",
       "  'I-department',\n",
       "  'I-department',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-scholarship',\n",
       "  'I-location',\n",
       "  'I-location',\n",
       "  'I-location',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'I-organization',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'I-department',\n",
       "  'I-department',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>',\n",
       "  '<PAD>']]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "predict(['中国人民大学第三十五届一二九合唱音乐节如期举行，信息学院分团委文化部将组织信院全体同学参加'], base_model, attr_dict['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}