{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnconda048fc75fe4ee43f1aa97608c8881ebba",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from utils.base_model import BiLSTM_CRF\n",
    "from utils.utils import prepare, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'path':'/home/peitian_zhang/Data/NER/labeled_train.txt',\n",
    "    'epochs': 150,\n",
    "    'batch_size': 100,\n",
    "    'embedding_dim': 300,\n",
    "    'hidden_dim': 150,\n",
    "    'device':'cuda:0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx, vocab, loader = prepare(hparams)\n",
    "hparams['vocab_size'] = len(vocab)\n",
    "hparams['seq_length'] = loader.dataset.max_length\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(hparams, tag2idx).to(hparams['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    record = next(iter(loader))\n",
    "    _, tag_seq = model(record['token'])\n",
    "    print(\"Prediction:{}\\n Ground Truth:{}\".format(tag_seq, record['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "for epoch in range(hparams['epochs']):\n",
    "    tqdm_ = tqdm(enumerate(loader))\n",
    "    total_loss = 0\n",
    "\n",
    "    for step,x in tqdm_:\n",
    "        model.zero_grad()\n",
    "        loss = model.neg_log_likelihood(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        tqdm_.set_description(\"epoch {:d} , step {:d} , loss: {:.4f}\".format(epoch+1, step, total_loss/(step+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    record = next(iter(loader))\n",
    "    _, tag_seq = model(record['token'])\n",
    "    print(\"Prediction:{}\\n Ground Truth:{}\".format(tag_seq, record['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(['窦志成获奖'],model,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}