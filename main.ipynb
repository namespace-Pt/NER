{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9616ec0cf0e0dd041cba3c8886d471a5cc72bbf20e2c795f4079199200777fdd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.4611, 0.4840, 0.5850],\n",
       "         [0.7357, 0.5802, 0.6525]]),\n",
       " tensor([0.5850, 0.7357]),\n",
       " tensor([2, 0]))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "a = torch.rand((2,3))\n",
    "b,c = a.max(dim=-1)\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "a = torch.rand((2,1,3))\n",
    "lstm = nn.LSTM(input_size=3, hidden_size=5)\n",
    "output,(ht,ct) = lstm(a)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(0,10,1)\n",
    "a = torch.tensor([[1],[2],[3],[4],[5]])\n",
    "b = torch.zeros((5,5))\n",
    "b+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([3.4076])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2.,3.]])\n",
    "torch.logsumexp(a,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[34.5524],\n",
       "        [34.4737],\n",
       "        [34.1782],\n",
       "        [34.4694],\n",
       "        [33.6329]])"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "tagset_size=10\n",
    "batch_size = 5\n",
    "START_TAG=0\n",
    "STOP_TAG=9\n",
    "tag2idx = {k:k for k in range(10)}\n",
    "transitions = torch.rand((10,10))\n",
    "\n",
    "\n",
    "feats = torch.rand((batch_size,10,10))\n",
    "# Do the forward algorithm to compute the partition function\n",
    "init_alphas = torch.full((batch_size, 1, tagset_size), -10000.)\n",
    "# START_TAG has all of the score.\n",
    "init_alphas[:,0,tag2idx[START_TAG]] = 0.\n",
    "\n",
    "# Wrap in a variable so that we will get automatic backprop\n",
    "forward_var = init_alphas\n",
    "\n",
    "# Iterate through the sentence\n",
    "for i in range(feats.shape[1]):\n",
    "    feat = feats[:,i,:]\n",
    "    emit_score = feat.view(batch_size, tagset_size, 1)\n",
    "    next_tag_var = forward_var + transitions + emit_score\n",
    "    forward_var = torch.logsumexp(next_tag_var,dim=-1).view(batch_size,1,tagset_size)\n",
    "\n",
    "terminal_var = forward_var + transitions[tag2idx[STOP_TAG]]\n",
    "alpha = torch.logsumexp(terminal_var,dim=-1)\n",
    "\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.8229, 0.9243, 0.0072],\n",
       "         [0.9102, 0.1859, 0.4592],\n",
       "         [0.9564, 0.7710, 0.3414]]),\n",
       " tensor([2, 0, 1, 0, 0]),\n",
       " tensor([2, 0, 0, 1, 2]),\n",
       " torch.Size([5]))"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "a = torch.rand((3,3))\n",
    "b = torch.zeros((5,5),dtype=torch.long).random_(0,3)\n",
    "\n",
    "a,b,b[:,0],b[:,2]\n",
    "\n",
    "a, b[:,0], b[:,2], a[b[:,0],b[:,2]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.5340, 0.3721, 0.4909],\n",
       "         [0.8295, 0.7753, 0.2160],\n",
       "         [0.2526, 0.1448, 0.0755],\n",
       "         [0.8207, 0.1910, 0.5065],\n",
       "         [0.4993, 0.5855, 0.4707]]),\n",
       " tensor([2, 0, 1, 1, 1]),\n",
       " tensor([[0.4909],\n",
       "         [0.8295],\n",
       "         [0.1448],\n",
       "         [0.1910],\n",
       "         [0.5855]]))"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "a = torch.rand((5,3))\n",
    "a, b[:,1], a.gather(dim=-1,index=b[:,1].unsqueeze(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.9712, 0.4389, 0.0791, 0.8923, 0.6217],\n",
       "         [0.5868, 0.5858, 0.8488, 0.2723, 0.8644],\n",
       "         [0.9808, 0.3711, 0.8156, 0.7759, 0.9682],\n",
       "         [0.3836, 0.2026, 0.3144, 0.1598, 0.5172],\n",
       "         [0.9821, 0.9851, 0.8777, 0.5495, 0.5109]]),\n",
       " tensor([4, 3]),\n",
       " tensor([0.6217, 0.8923]))"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "a = torch.rand((5,5))\n",
    "b = torch.zeros((2,5),dtype=torch.long).random_(0,5)\n",
    "\n",
    "a, b[:,-1], a[0,b[:,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 2],\n",
       "        [6, 6]])"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[2,3,4],[4,5,6]])\n",
    "b = torch.tensor([[0,1],[1,0],[2,2]])\n",
    "a.gather(dim=-1, index=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = torch.rand((10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 1, 10]) torch.Size([5, 1])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[17.6795],\n",
       "         [17.1391],\n",
       "         [17.3876],\n",
       "         [16.9612],\n",
       "         [16.0013]]),\n",
       " [tensor([[0],\n",
       "          [4],\n",
       "          [7],\n",
       "          [4],\n",
       "          [1]]),\n",
       "  tensor([[7],\n",
       "          [5],\n",
       "          [7],\n",
       "          [5],\n",
       "          [3]]),\n",
       "  tensor([[2],\n",
       "          [7],\n",
       "          [7],\n",
       "          [5],\n",
       "          [6]]),\n",
       "  tensor([[4],\n",
       "          [2],\n",
       "          [2],\n",
       "          [4],\n",
       "          [9]]),\n",
       "  tensor([[8],\n",
       "          [3],\n",
       "          [3],\n",
       "          [5],\n",
       "          [7]]),\n",
       "  tensor([[1],\n",
       "          [6],\n",
       "          [6],\n",
       "          [4],\n",
       "          [2]]),\n",
       "  tensor([[3],\n",
       "          [3],\n",
       "          [2],\n",
       "          [5],\n",
       "          [4]]),\n",
       "  tensor([[4],\n",
       "          [0],\n",
       "          [7],\n",
       "          [5],\n",
       "          [8]]),\n",
       "  tensor([[5],\n",
       "          [7],\n",
       "          [2],\n",
       "          [7],\n",
       "          [3]]),\n",
       "  tensor([[0],\n",
       "          [2],\n",
       "          [6],\n",
       "          [2],\n",
       "          [6]])])"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "tagset_size=10\n",
    "START_TAG=0\n",
    "STOP_TAG=9\n",
    "tag2idx = {k:k for k in range(10)}\n",
    "transitions = torch.rand((10,10))\n",
    "\n",
    "feats = torch.rand((batch_size, 10,10))\n",
    "\n",
    "backpointers = []\n",
    "# Initialize the viterbi variables in log space\n",
    "init_vvars = torch.full((batch_size, 1, tagset_size), -10000.)\n",
    "init_vvars[:, 0, tag2idx[START_TAG]] = 0.\n",
    "\n",
    "# forward_var at step i holds the viterbi variables for step i-1\n",
    "forward_var = init_vvars    # [1,tag_size]\n",
    "for i in range(feats.shape[1]):\n",
    "    feat = feats[:,i,:]\n",
    "\n",
    "    # [tag_size]\n",
    "    bptrs_t = []  # holds the backpointers for this step\n",
    "    viterbivars_t = []  # holds the viterbi variables for this step\n",
    "    next_tag_var = forward_var + transitions + feat.view(batch_size, tagset_size, 1)\n",
    "    best_tag_var, best_tag_id = torch.max(next_tag_var, dim=-1)\n",
    "    backpointers.append(best_tag_id)\n",
    "    forward_var = best_tag_var.view(batch_size, 1, tagset_size)\n",
    "\n",
    "    # for next_tag in range(tagset_size):\n",
    "    #     # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "    #     # previous step, plus the score of transitioning\n",
    "    #     # from tag i to next_tag.\n",
    "    #     # We don't include the emission scores here because the max\n",
    "    #     # does not depend on them (we add them in below)\n",
    "    #     next_tag_var = forward_var + transitions[next_tag] # [1,tag_size]\n",
    "    #     best_tag_id = torch.argmax(next_tag_var, dim=-1)\n",
    "    #     bptrs_t.append(best_tag_id) # best pre-tag of each next-tag\n",
    "    #     viterbivars_t.append(next_tag_var[0][best_tag_id].view(1)) # value of variable\n",
    "    # # Now add in the emission scores, and assign forward_var to the set\n",
    "    # # of viterbi variables we just computed\n",
    "    # forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1) # [1,tag_size]\n",
    "    # backpointers.append(bptrs_t)\n",
    "\n",
    "# Transition to STOP_TAG\n",
    "terminal_var = forward_var + transitions[tag2idx[STOP_TAG]]\n",
    "path_score, best_tag_id = torch.max(terminal_var, dim=-1)\n",
    "print(terminal_var.shape, path_score.shape)\n",
    "best_path = [best_tag_id]\n",
    "\n",
    "for bptrs_t in reversed(backpointers):\n",
    "    best_tag_id = bptrs_t.gather(dim=-1,index=best_tag_id)\n",
    "    best_path.append(best_tag_id)\n",
    "# Pop off the start tag (we dont want to return that to the caller)\n",
    "start = best_path.pop()\n",
    "best_path.reverse()\n",
    "path_score, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]]]),\n",
       " tensor([[[0.7718, 0.3404, 0.1011, 0.5803, 0.4554],\n",
       "          [0.4495, 0.2544, 0.5104, 0.6436, 0.6804],\n",
       "          [0.0972, 0.7416, 0.5514, 0.8449, 0.8534],\n",
       "          [0.1062, 0.9802, 0.0083, 0.7874, 0.5352],\n",
       "          [0.7366, 0.2296, 0.8006, 0.2526, 0.0581]]]),\n",
       " tensor([[[-0.2282, -0.6596, -0.8989, -0.4197, -0.5446],\n",
       "          [-0.5505, -0.7456, -0.4896, -0.3564, -0.3196],\n",
       "          [-0.9028, -0.2584, -0.4486, -0.1551, -0.1466],\n",
       "          [-0.8938, -0.0198, -0.9917, -0.2126, -0.4648],\n",
       "          [-0.2634, -0.7704, -0.1994, -0.7474, -0.9419]],\n",
       " \n",
       "         [[-0.2282, -0.6596, -0.8989, -0.4197, -0.5446],\n",
       "          [-0.5505, -0.7456, -0.4896, -0.3564, -0.3196],\n",
       "          [-0.9028, -0.2584, -0.4486, -0.1551, -0.1466],\n",
       "          [-0.8938, -0.0198, -0.9917, -0.2126, -0.4648],\n",
       "          [-0.2634, -0.7704, -0.1994, -0.7474, -0.9419]],\n",
       " \n",
       "         [[-0.2282, -0.6596, -0.8989, -0.4197, -0.5446],\n",
       "          [-0.5505, -0.7456, -0.4896, -0.3564, -0.3196],\n",
       "          [-0.9028, -0.2584, -0.4486, -0.1551, -0.1466],\n",
       "          [-0.8938, -0.0198, -0.9917, -0.2126, -0.4648],\n",
       "          [-0.2634, -0.7704, -0.1994, -0.7474, -0.9419]],\n",
       " \n",
       "         [[-0.2282, -0.6596, -0.8989, -0.4197, -0.5446],\n",
       "          [-0.5505, -0.7456, -0.4896, -0.3564, -0.3196],\n",
       "          [-0.9028, -0.2584, -0.4486, -0.1551, -0.1466],\n",
       "          [-0.8938, -0.0198, -0.9917, -0.2126, -0.4648],\n",
       "          [-0.2634, -0.7704, -0.1994, -0.7474, -0.9419]],\n",
       " \n",
       "         [[-0.2282, -0.6596, -0.8989, -0.4197, -0.5446],\n",
       "          [-0.5505, -0.7456, -0.4896, -0.3564, -0.3196],\n",
       "          [-0.9028, -0.2584, -0.4486, -0.1551, -0.1466],\n",
       "          [-0.8938, -0.0198, -0.9917, -0.2126, -0.4648],\n",
       "          [-0.2634, -0.7704, -0.1994, -0.7474, -0.9419]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "a = torch.full((5, 5, 1), -1.)\n",
    "b = torch.rand((1,5,5))\n",
    "a,b,a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "init_alphas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}